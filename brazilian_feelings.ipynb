{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brazilian_feelings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/tyronedamasceno/brazilian-feelings/blob/master/brazilian_feelings.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "g2E2M-Zlzj-Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Análise de sentimentos por região\n",
        "\n",
        "Uma das áreas de ciência de dados que tem apresentado grande crescimento é a análise de sentimentos.\n",
        "\n",
        "Nesse notebook vamos ver uma forma de analisar como está o sentimento dos usuários do twitter sobre ~~politica~~ um determinado assunto. Além disso essa análise poderá ser feitas sobre as regiões, visto que um mesmo assunto pode causar diferentes reações em locais variados."
      ]
    },
    {
      "metadata": {
        "id": "Iae0kxVQ39it",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pré-requisitos\n",
        "\n",
        "- Python3\n",
        "- TextBlob\n",
        "- TweePy\n",
        "- Numpy\n",
        "- Conta no twitter\n"
      ]
    },
    {
      "metadata": {
        "id": "tB1uwxoRyZNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b08ee5f2-a463-4ac8-bb7a-5ad95fa8c136"
      },
      "cell_type": "code",
      "source": [
        "!pip install tweepy textblob numpy\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweepy\n",
            "  Downloading https://files.pythonhosted.org/packages/05/f1/2e8c7b202dd04117a378ac0c55cc7dafa80280ebd7f692f1fa8f27fd6288/tweepy-3.6.0-py2.py3-none-any.whl\n",
            "Collecting textblob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/18/7f55c8be6d68ddc4036ffda5382ca51e23a1075987f708b9123712091af1/textblob-0.15.1-py2.py3-none-any.whl (631kB)\n",
            "\u001b[K    100% |████████████████████████████████| 634kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Collecting PySocks>=1.5.7 (from tweepy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/12/6bf1d764f128636cef7408e8156b7235b150ea31650d0260969215bb8e7d/PySocks-1.6.8.tar.gz (283kB)\n",
            "\u001b[K    100% |████████████████████████████████| 286kB 28.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.11.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.18.4)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2018.10.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.22)\n",
            "Building wheels for collected packages: PySocks\n",
            "  Running setup.py bdist_wheel for PySocks ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/22/5c/b5/12e0dfdfa85bea67b23628b6425fae715c687e947a45ee3df9\n",
            "Successfully built PySocks\n",
            "Installing collected packages: PySocks, tweepy, textblob\n",
            "Successfully installed PySocks-1.6.8 textblob-0.15.1 tweepy-3.6.0\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WaK-_2xd5WE_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Perfil de desenvolvedor\n",
        "\n",
        "Após instalar as bibliotecas será necessário (se você não possuir ainda) criar uma conta de desenvolvedor no twitter.\n",
        "\n",
        "Isso pode ser feito acessando a página de [desenvolvedores](https://developer.twitter.com) do twitter (logado na sua conta) e clicar em _apply for a development account_\n",
        "\n",
        "Após sua conta ser aceita (as vezes é rápido, as vezes demora...) você precisa criar um app e guardar as credenciais dele.\n",
        "\n",
        "- Consumer API keys\n",
        "- Access token & access token secret"
      ]
    },
    {
      "metadata": {
        "id": "_kDiCId5-8XT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vamos a luta!\n",
        "\n",
        "Agora de posse de tudo que é necessário, mãos a obra!"
      ]
    },
    {
      "metadata": {
        "id": "MB7Pz0ox_D3b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import numpy as np\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IeOy1Fxj-YFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "consumer_key='W313gbqFgBk7bJrXYvxbFJCeu'\n",
        "consumer_secret='pGXNhrHKeymEGpmXr3Tgng7TdQJ8DQ4ZvC1X0GsielppPACbZE'\n",
        "\n",
        "access_token='1050013375940517888-rehrUfWWzUc3LXeHYsXolu8q2UoxaS'\n",
        "access_token_secret='Q8t7SLe3olzODJ800GkbkHef8NMnXTpaT6H6a7s2wrAh2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiNuiRBO_QY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora, pra confirmar se deu tudo certo, façamos a autenticação na API do twitter"
      ]
    },
    {
      "metadata": {
        "id": "SI_-9Os1_e8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e1ac87e-f11b-47a5-9e26-e26b45c6c0ac"
      },
      "cell_type": "code",
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
        "auth.set_access_token(access_token,access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "api"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tweepy.api.API at 0x7fe18e695ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "73zGsI88_-Ig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se deu tudo certo, vamos ao que interessa, buscar os dados para trabalhar!!!"
      ]
    },
    {
      "metadata": {
        "id": "0lxp4d4DADUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tweets = api.search('Bolsonaro -filter:retweets')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMBJzbFuAN5a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O trecho \"-filter:retweets\" serve para que os retweets não sejam trazidos para nossa base, evitando que haja repetição de dados\n",
        "\n",
        "Agora, vamos iterar sobre todos os tweets recuperados, colocando o conteúdo de texto (tweet.text) em um TextBlob"
      ]
    },
    {
      "metadata": {
        "id": "52ugvHb4ANLi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tweet in tweets:\n",
        "  print(TextBlob(tweet.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7BsWI7rNUHQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Um \"problema\" que temos é que o algoritmo de análise de sentimentos do TextBlob foi treinado em inglês, portanto usaremos um recurso que faz a tradução para inglês dos tweets que tiverem em outros idiomas. \n",
        "\n",
        "Primeiro criaremos uma função que detecta se o tweet está em inglês"
      ]
    },
    {
      "metadata": {
        "id": "UvMHw8T4NThW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def is_english(text):\n",
        "  if text.detect_language() == \"en\":\n",
        "    return True\n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pok-LpJfOHwr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dentro do laço for vamos verificar se o texto está em inglês, se não estiver faremos a tradução deste. Em seguida, faremos a análise de sentimentos"
      ]
    },
    {
      "metadata": {
        "id": "NA1Zj1jrOXG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for tweet in tweets:\n",
        "  text = TextBlob(tweet.text)\n",
        "  \n",
        "  if not is_english(text):\n",
        "    text = TextBlob(str(text.translate(to='en')))\n",
        "  \n",
        "  #print('Tweet: ' + tweet.text)\n",
        "  #print('Polarity: ' + str(text.sentiment.polarity) + \" \\ \" + str(text.sentiment.subjectivity))\n",
        "  #print('.....................')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGjQsLZxP7QP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Agora, um pouco de teoria\n",
        "\n",
        "Do nada um monte de dados que não sabemos de onde vem, né? Calma que vamos explicar tudo...\n",
        "\n",
        "**Polarity**:  Um valor entre -1.0 e 1.0, onde -1.0 se refere a uma polaridade 100% negativa, 1.0 uma polaridade 100% positiva e o 0 se refere a neutralidade\n",
        "\n",
        "**Subjectivity**: Um valor entre 0.0 e 1.0, onde 0.0 se refere a um valor 100% objetivo e 1.0 se refere a um valor 100%subjetivo\n",
        "\n",
        "Sentenças objetivas normalmente possuem fatos ou informaçãoes, enquanto sentenças subjetivas expressam sentimentos pessoais e opiniões"
      ]
    },
    {
      "metadata": {
        "id": "_kUcqQbGQ9bV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Voltando ao trabalho\n",
        "\n",
        "Agora que sabemos o que os dados significam, devemos ignorar valores com onde sua polaridade é neutra e são 100% objetivas, visto que se referem a fatos, e fatos não expressam sentimentos.\n",
        "\n",
        "Vamos juntar tudo que vimos dentro de uma função para ficar mais organizado"
      ]
    },
    {
      "metadata": {
        "id": "l_ZfbGUkRfJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_analysis():\n",
        "    polarities = []\n",
        "\n",
        "    for tweet in tweets:\n",
        "        text = TextBlob(tweet.text)\n",
        "\n",
        "        if not is_english(text):\n",
        "            text = TextBlob(str(text.translate(to='en')))\n",
        "            \n",
        "        if (text.sentiment.polarity != 0.0 and text.sentiment.subjectivity != 0.0):\n",
        "            polarities.append(text.sentiment.polarity)\n",
        "\n",
        "        #print('Tweet: ' + tweet.text)\n",
        "        #print('Polarity: ' + str(text.sentiment.polarity) + \" \\ \" + str(text.sentiment.subjectivity))\n",
        "        #print('.....................')\n",
        "        \n",
        "    \n",
        "    return polarities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFcJawjXRtEV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "E usaremos o **NumPy** para calcular a média das polaridades"
      ]
    },
    {
      "metadata": {
        "id": "kSppLJV_R74N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5d5e6b68-89c7-454a-b0e0-f71d61dfcac7"
      },
      "cell_type": "code",
      "source": [
        "polarity_mean = np.mean(tweet_analysis())\n",
        "\n",
        "print('Média: ' + str(polarity_mean))\n",
        "if(polarity_mean > 0.0):\n",
        "    print('POSITIVE')\n",
        "else:\n",
        "    print('NEGATIVE')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média: 0.06493055555555555\n",
            "POSITIVE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51RKxxORS8jn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Êba, pronto??? Ainda não\n",
        "\n",
        "De fato criamos um analisador de tweets, mas esse projeto vai muito além disso.\n",
        "\n",
        "Vamos alterar a forma de busca dos tweets para que possamos determinar o número de tweets recuperados e que esses sejam os mais recentes"
      ]
    },
    {
      "metadata": {
        "id": "9AOpWigOvz0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tweets = tweepy.Cursor(api.search, q=\"Python Brasil -filter:retweets\", result_type=\"recent\").items(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FhyslvSBwgDI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modificando um pouco as coisas\n",
        "\n",
        "Agora, faremos uma mudança na nossa função `tweet_analysis()` para que essa retorne um dicionário com as polaridades e subjetividades de cada tweet, bem como ela que receba o termo a ser passado como query e o numero de tweets a serem procurados."
      ]
    },
    {
      "metadata": {
        "id": "EXg_q_mzxSaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_analysis(query, items=20):\n",
        "    \n",
        "    tweets = tweepy.Cursor(api.search, wait_on_rate_limit=True, q=query + \" -filter:retweets\", result_type=\"recent\").items(items)\n",
        "    polarities = []\n",
        "    subjectivities = []\n",
        "    \n",
        "    for tweet in tweets:\n",
        "        text = TextBlob(tweet.text)\n",
        "        #if not is_english(text):\n",
        "        #    text = TextBlob(str(text.translate(to='en')))\n",
        "            \n",
        "        \n",
        "        if (text.sentiment.polarity != 0.0 and text.sentiment.subjectivity != 0.0):\n",
        "            polarities.append(text.sentiment.polarity)\n",
        "            subjectivities.append(text.sentiment.subjectivity)\n",
        "        \n",
        "    \n",
        "    return {'polarity': polarities, 'subjectivity':subjectivities}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yaAcRXKD4B_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos também criar uma função que pega a média ponderada dos tweets a partir da sua subjetividade e outra para imprimir os resultados"
      ]
    },
    {
      "metadata": {
        "id": "LaxC5O1Nxz7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_weighted_polarity_mean(valid_tweets):\n",
        "    return np.average(valid_tweets['polarity'],weights=valid_tweets['subjectivity'])\n",
        "\n",
        "def get_polarity_mean(valid_tweets):\n",
        "    return np.mean(valid_tweets['polarity'])\n",
        "  \n",
        "def print_result(mean):\n",
        "    if mean > 0.0:\n",
        "        print('POSITIVE')\n",
        "    elif mean == 0.0:\n",
        "        print('NEUTRO')\n",
        "    else:\n",
        "        print('NEGATIVE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wOt1IU0y5VLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Finalizando a análise\n",
        "\n",
        "Vamos criar uma função principal que centraliza a análise:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "i3tMsGnn59OY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def do_analysis():\n",
        "  query = input(\"Entre a query de analise: \")\n",
        "  analysis = tweet_analysis(query)\n",
        "\n",
        "  print('MÉDIA PONDERADA: ' + str(get_weighted_polarity_mean(analysis)))\n",
        "  print_result(get_weighted_polarity_mean(analysis))\n",
        "\n",
        "  print('MÉDIA: ' + str(get_polarity_mean(analysis)))\n",
        "  print_result(get_polarity_mean(analysis))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZvL47DX_6Drk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "31aee190-9147-49db-e93b-e66e0f01961e"
      },
      "cell_type": "code",
      "source": [
        "do_analysis()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entre a query de analise: Trump\n",
            "MÉDIA PONDERADA: 0.15503915599211138\n",
            "POSITIVE\n",
            "MÉDIA: 0.08037918871252207\n",
            "POSITIVE\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}