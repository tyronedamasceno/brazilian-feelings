{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_crawler.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1M86Fx40kzcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tweet Crawler**\n",
        "\n",
        "Este caderno é responsável por coletar tweets filtrados por algumas palavras chaves, analisar sentimentos no texto e inserir as coordenadas de onde os tweets foram postados.\n",
        "\n",
        "Ao fim, um arquivo csv é gerado para analíse dos resultados.\n",
        "\n",
        "O objetivo geral/motivação foi capturar o sentimento dos postos a respeito da eleição para presidente do Brasil em 28/10/2018, uma segunda parte do trabalho também está disponivel onde pode-se visualizar os resultados (sentimentos) por região. \n",
        "\n",
        "Em todo caso, os scripts abaixo podem ser usados em qualquer contexto que se desejar, bastando apenas inserir as chaves da API do Tweet e os termos que se desejam localizar.\n"
      ]
    },
    {
      "metadata": {
        "id": "cW2vff3gcpvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1159
        },
        "outputId": "0c5fab51-eaaf-42b9-da56-a264c5163ca8"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Instalando dependências\n",
        "'''\n",
        "\n",
        "!pip install textblob==0.15.1\n",
        "!pip install tweepy==3.6.0\n",
        "!pip install geocoder\n",
        "\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/02/bae88c4aaea4256d890adbf3f7cf33e59a443f9985cf91cd08a35656676a/numpy-1.15.2-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 2.4MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.15.2\n",
            "Collecting textblob==0.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/18/7f55c8be6d68ddc4036ffda5382ca51e23a1075987f708b9123712091af1/textblob-0.15.1-py2.py3-none-any.whl (631kB)\n",
            "\u001b[K    100% |████████████████████████████████| 634kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob==0.15.1) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob==0.15.1) (1.11.0)\n",
            "Installing collected packages: textblob\n",
            "Successfully installed textblob-0.15.1\n",
            "Collecting tweepy==3.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/f1/2e8c7b202dd04117a378ac0c55cc7dafa80280ebd7f692f1fa8f27fd6288/tweepy-3.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy==3.6.0) (1.11.0)\n",
            "Collecting PySocks>=1.5.7 (from tweepy==3.6.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/12/6bf1d764f128636cef7408e8156b7235b150ea31650d0260969215bb8e7d/PySocks-1.6.8.tar.gz (283kB)\n",
            "\u001b[K    100% |████████████████████████████████| 286kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy==3.6.0) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy==3.6.0) (2.18.4)\n",
            "Requirement already satisfied: oauthlib>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy==3.6.0) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy==3.6.0) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy==3.6.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy==3.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy==3.6.0) (1.22)\n",
            "Building wheels for collected packages: PySocks\n",
            "  Running setup.py bdist_wheel for PySocks ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/22/5c/b5/12e0dfdfa85bea67b23628b6425fae715c687e947a45ee3df9\n",
            "Successfully built PySocks\n",
            "Installing collected packages: PySocks, tweepy\n",
            "Successfully installed PySocks-1.6.8 tweepy-3.6.0\n",
            "Collecting geocoder\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/6b/13166c909ad2f2d76b929a4227c952630ebaf0d729f6317eb09cbceccbab/geocoder-1.38.1-py2.py3-none-any.whl (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from geocoder) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from geocoder) (2.18.4)\n",
            "Collecting ratelim (from geocoder)\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/98/7e6d147fd16a10a5f821db6e25f192265d6ecca3d82957a4fdd592cad49c/ratelim-0.1.6-py2.py3-none-any.whl\n",
            "Collecting click (from geocoder)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ratelim->geocoder) (4.3.0)\n",
            "Installing collected packages: ratelim, click, geocoder\n",
            "Successfully installed click-7.0 geocoder-1.38.1 ratelim-0.1.6\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utWPAQGbdSNE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Importando bibliotecas e setando as chaves de acesso a API do tweet\n",
        "\"\"\"\n",
        "\n",
        "import tweepy\n",
        "\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import geocoder\n",
        "\n",
        "consumer_key= \"CONSUMER_KEY\"\n",
        "consumer_secret= \"CONSUMER_SECRET\"\n",
        "\n",
        "access_token= \"TWEET_ACCESS_TOKEN\"\n",
        "access_token_secret= \"TWEET_ACCESS_TOKEN_SECRET\"\n",
        "\n",
        "\n",
        "''' Setando o acesso ao tweet '''\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
        "auth.set_access_token(access_token,access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "quSyf3F6gqnm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Limpando os dados e coletando a geolocalizacao\n",
        "\"\"\"\n",
        "\n",
        "from time import gmtime, strftime, time\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Uma dependencia da biblioteca de análise de sentimentos é que o texto esteja em inglês.\n",
        "\"\"\"\n",
        "def is_english(text):\n",
        "    if text.detect_language() == 'en':\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "def tweet_analisys(query, ntweets=20):\n",
        "  \"\"\"\n",
        "  Função para criar um dataFrame com os dados coletados, \n",
        "  incluindo a latitude e longitude de onde o usuário do tweet estava.\n",
        "  \"\"\"\n",
        "\n",
        "  tweets = tweepy.Cursor(api.search, q=\"{} -filter:retweets\".format(query), result_type=\"recent\", geo_enabled=True).items(ntweets)\n",
        "\n",
        "  \n",
        "  df = pd.DataFrame()\n",
        "  i = 0\n",
        "  for tweet in tweets:\n",
        "      phrase = TextBlob(tweet.text)\n",
        "\n",
        "      if tweet.user.location:\n",
        "        if not is_english(phrase):\n",
        "          try:\n",
        "            phrase = TextBlob(str(phrase.translate(to='en')))\n",
        "            time.sleep(1)\n",
        "          except Exception as e:\n",
        "            print(\"Um erro na tradução aconteceu na linha {}: {}\".format(i,e))\n",
        "            pass\n",
        "\n",
        "        df.loc[i, 'texto'] = tweet.text\n",
        "        df.loc[i, 'polarity'] = str(phrase.sentiment.polarity)\n",
        "        df.loc[i, 'subjectivity'] = str(phrase.sentiment.subjectivity)\n",
        "        df.loc[i, 'location'] = tweet.user.location\n",
        "        g = geocoder.arcgis(df.loc[i, 'location'])\n",
        "        df.loc[i,'Latitude'] = g.lat\n",
        "        df.loc[i,'Longitude'] = g.lng\n",
        "        i = i+1\n",
        "  \n",
        "  unique = strftime(\"%Y%m%d_%H%M%S\", gmtime())\n",
        "  \n",
        "  print(\"Criando Extrato aplicado em:\", query)\n",
        "  df.to_csv(\"{}_{}.csv\".format(query,unique), sep=';')\n",
        "  return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    [tweet_analisys(q, 3000) for q in [\"Bolsonaro\", \"Haddad\"]]\n",
        "    print(\"done\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}